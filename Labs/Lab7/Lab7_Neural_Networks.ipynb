{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RNN vs LSTM\n",
        "\n",
        "All RNNs have feedback loops in the recurrent layer. This lets them maintain information in 'memory' over time. But, it can be difficult to train standard RNNs to solve problems that require learning long-term temporal dependencies. This is because the gradient of the loss function decays exponentially with time (called the vanishing gradient problem). LSTM networks are a type of RNN that uses special units in addition to standard units. LSTM units include a 'memory cell' that can maintain information in memory for long periods of time. A set of gates is used to control when information enters the memory, when it's output, and when it's forgotten."
      ],
      "metadata": {
        "id": "uqj39PUPnFYe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_0YngShg-lb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'yelp_polarity_reviews/subwords8k'\n",
        "text_feature = 'text'\n",
        "encoder_subwords = 50\n",
        "delimiter = '---------'\n",
        "example = \"the park is nice and quiet\" # 1, .., 13, .., 3, ..\n",
        "examples_are_correct = \"examples are correct\"\n",
        "examples_are_not_correct = \"examples are not correct\"\n",
        "activation_type = 'relu'\n",
        "learning_rate = 1e-4\n",
        "metrics_type = 'accuracy'\n",
        "model_name = 'lab7.h5'\n",
        "model_weights_name = \"lab7_weights.h5\""
      ],
      "metadata": {
        "id": "wvpiQyPO2QAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyk_5ujzK81j"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYLqudZ6h7mF"
      },
      "outputs": [],
      "source": [
        "(train_dataset, test_dataset), dataset_info = tfds.load(name=dataset_name,\n",
        "                                          split=(tfds.Split.TRAIN, tfds.Split.TEST),\n",
        "                                          with_info=True,\n",
        "                                          as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEUbuzOtlTd6",
        "outputId": "0131f0af-2f4b-4c6e-a07b-fb607fe8cccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'test': <tfds.core.SplitInfo num_examples=38000>, 'train': <tfds.core.SplitInfo num_examples=560000>}\n",
            "---------\n",
            "8176\n",
            "---------\n",
            "['the_', ', ', 'and_', '. ', 'I_', 'a_', 'to_', 'was_', 'of_', '.  ', 's_', 'in_', 'is_', 'for_', 'it_', 'that_', 't_', 'my_', 'with_', 'on_', 'but_', 'The_', 'you_', 'this_', 'have_', 'they_', 'not_', 'we_', 'had_', 'at_', 'were_', '.\\\\', 'are_', 'be_', 'so_', 'as_', 'it', 'd_', 'place_', 'like_', 'me_', ' (', 'just_', 'get_', '. \\\\', 'ing_', 'ed_', 'our_', 'food_', 'or_']\n"
          ]
        }
      ],
      "source": [
        "encoder = dataset_info.features[text_feature].encoder\n",
        "\n",
        "print(dataset_info.splits)\n",
        "print(delimiter)\n",
        "print(encoder.vocab_size)\n",
        "print(delimiter)\n",
        "print(encoder.subwords[:encoder_subwords])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtjwE0vLlaJc",
        "outputId": "a6e861fd-8172-4b5e-86b4-653c3aaec380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1984, 13, 151, 3, 5122]\n"
          ]
        }
      ],
      "source": [
        "example_ids = encoder.encode(example)\n",
        "print(example_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKWrA_DOlm9r",
        "outputId": "29b0478e-22a9-4a61-d906-21f3a50b718b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the park is nice and quiet\n"
          ]
        }
      ],
      "source": [
        "example_from_ids = encoder.decode(example_ids)\n",
        "print(example_from_ids)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (example == example_from_ids):\n",
        "  print(examples_are_correct)\n",
        "else:\n",
        "  print(examples_are_not_correct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSjaPtIp8vzX",
        "outputId": "ffbdc035-115e-4975-b6cf-354c5d963544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "examples are correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8_jFBfJLwaH"
      },
      "source": [
        "# Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK8N8CqZl6x3"
      },
      "outputs": [],
      "source": [
        "buffer_size = 800\n",
        "batch_size = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_herF8Bmp6C"
      },
      "outputs": [],
      "source": [
        "train_data = train_dataset.shuffle(buffer_size).padded_batch(batch_size = batch_size, padded_shapes = ([None],[]))\n",
        "test_data = test_dataset.shuffle(buffer_size).padded_batch(batch_size = batch_size, padded_shapes = ([None],[]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OirkSU8aL2SC"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjVlvFOqm2Gr"
      },
      "outputs": [],
      "source": [
        "# 1) Word Embeddings = trandsforms integer = [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
        "# 2) Bi-directional layer =  LSTMs have been one-way models, also\n",
        "  # called unidirectional ones. In other words, sequences such as\n",
        "  # tokens (i.e. words) are read in a left-to-right or right-to-left fashion.\n",
        "  # This does not necessarily reflect good practice, as more recent Transformer\n",
        "  # based approaches like BERT suggest. In fact, bidirectionality - or processing \n",
        "  # the input in a left-to-right and a right-to-left fashion,\n",
        "  # can improve the performance of your Machine Learning model.\n",
        "# 3) Dense Layer = Just your regular densely-connected NN layer\n",
        "# 4) Binary Output\n",
        "model = tf.keras.Sequential([tf.keras.layers.Embedding(encoder.vocab_size, batch_size),\n",
        "                           tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 64)),\n",
        "                           tf.keras.layers.Dense(units = 64, activation = activation_type),\n",
        "                           tf.keras.layers.Dense(units = 1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "467e9v9locka"
      },
      "outputs": [],
      "source": [
        "# BinaryCrossEntropy = two label classes\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
        "              loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
        "              metrics = [metrics_type])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7d0ErbFL5uI"
      },
      "source": [
        "# Model Training & Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmhxegvppdJr",
        "outputId": "452692c0-457b-48f9-fb6b-ad364b7f9541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "11200/11200 [==============================] - 2233s 199ms/step - loss: 0.2191 - accuracy: 0.9086 - val_loss: 0.1757 - val_accuracy: 0.9420\n",
            "Epoch 2/5\n",
            "11200/11200 [==============================] - 2224s 199ms/step - loss: 0.1731 - accuracy: 0.9324 - val_loss: 0.1632 - val_accuracy: 0.9400\n",
            "Epoch 3/5\n",
            "11200/11200 [==============================] - 2223s 198ms/step - loss: 0.1608 - accuracy: 0.9370 - val_loss: 0.1591 - val_accuracy: 0.9380\n",
            "Epoch 4/5\n",
            "11200/11200 [==============================] - 2219s 198ms/step - loss: 0.1476 - accuracy: 0.9426 - val_loss: 0.1374 - val_accuracy: 0.9500\n",
            "Epoch 5/5\n",
            "11200/11200 [==============================] - 2209s 197ms/step - loss: 0.1283 - accuracy: 0.9504 - val_loss: 0.1354 - val_accuracy: 0.9600\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "validation_cycles = 10\n",
        "\n",
        "# workers = maximum number of processes to spin up when using process-based threading\n",
        "hist = model.fit(train_data,\n",
        "                 epochs = epochs,\n",
        "                 validation_data = test_data,\n",
        "                 validation_steps = validation_cycles,\n",
        "                 workers = 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12r5QLd6INWf"
      },
      "outputs": [],
      "source": [
        "model.save(model_name)\n",
        "model.save_weights(model_weights_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIYp7yEGL_fJ"
      },
      "source": [
        "# Trained Model Performance Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zisj0UNLPDZo",
        "outputId": "3403056c-9a17-41d0-ae25-b031e58532bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "760/760 [==============================] - 72s 95ms/step - loss: 0.1374 - accuracy: 0.9497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj8Xv2SDIceg",
        "outputId": "3980a1da-0503-4805-e764-d6418da4fcb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9496579170227051\n",
            "Loss: 0.13735729455947876\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy:', test_acc)\n",
        "print('Loss:', test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPnJMxuD8TDB"
      },
      "source": [
        "## Model Evaluation\n",
        "\n",
        "If the prediction is >= 0.5, it is positive else it is negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoceQA6i8TDB"
      },
      "outputs": [],
      "source": [
        "def predict(text):\n",
        "    encoded = encoder.encode(text)\n",
        "    encoded = tf.cast(encoded, tf.float32)\n",
        "    return (model.predict(tf.expand_dims(encoded, 0)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = [\"This book is good\",\n",
        "                 \"This book is bad\",\n",
        "                 \"I'd rather have paid to prevent them from releasing this\",\n",
        "                 \"this game came with none of the promised improvements and didn't even fix the old bugs\",\n",
        "                 \"What an incredible game this is a wholesome openworld game I dont understand why some of the idiots are writing emotional review how could people without rational judgment write a review?\",\n",
        "                 \"Great feeling of exploration, the world is huge\",\n",
        "                 \"I really like this food from the store\"]"
      ],
      "metadata": {
        "id": "c3CPgQYIKQma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4puJSA78TDC",
        "outputId": "52b46a82-446a-43ec-b85a-e3e46cb9ea7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.53918487]]\n",
            "[[-1.7114202]]\n",
            "[[-1.8774989]]\n",
            "[[-2.3849142]]\n",
            "[[1.4655215]]\n",
            "[[3.0931892]]\n",
            "[[0.05660355]]\n"
          ]
        }
      ],
      "source": [
        "for text in example_texts:\n",
        "  print(predict(text))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Lab7-Neural-Networks",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}